# 一、疫情管理系统

## 疫情大数据平台

数据爬取/生成 -> Kafka -> Spark -> MySQL -> 前端/云平台


> **HttpClient 与 jsoup**

HttpClient 获取网页内容，使用 jsoup 解析网页内容。

> **Zookeeper**

- 主要功能
  - 统一配置管理
  - 统一命名服务
  - 分布式锁
  - 集群状态

- 功能实现：节点+监听器

> **Kafka**

> **Spark**

- 利用SparkStreaming实现
  - 准备SparkStreaming的开发环境
  - 准备Kafka的连接参数
  - 连接kafka获取消息
  - 实时处理数据
  - 将处理分析的结果存入到MySql
  - 开启SparkStreaming任务并等待结束


- Spark整合Kafka的两种方式
  - Receiver 模式
    - 通过KafkaUtils.creatDStream -- API创建
    - 会有一个Receiver作为常驻Task，运行在Executor进程中，一直等待数据到来
    - 一个Reciver效率会比较低，可以使用多个Receiver,但是多个Receiver中的数据有需要手动进行合并，很麻烦。同时如果其中某个Receiver挂了，会导致数据丢失，需要开启WAL预写日志来保证数据安全，但效率低
    - Receiver模式使用Zookeeper模式来连接Kafka(Kafka的最新版本中已经不推荐使用该方法了)
    - Receiver模式中使用的是Kafka的高阶API，offset由Receiver提交到ZK中(Kafka的新版本中Offset默认存储在默认主题__consumer__offset中的，不推荐存入ZK中)，容易和Spark维护在Checkpoint中的offset不一致
  - Direct模式
    - 由KafkaUtils.createDirectStream--API创建
    - Direct模式是直接连接到Kafka的各个分区，并拉取得数据，提高了数据读取的并发能力
    - Direct模式使用的是kafka低阶API，可以自己维护偏移量到任何地方
    - 默认是由Spark提交到默认主题/CheckPoint
    - Direct模式+手动操作可以保证数据的Exactly-Once精准一次(数据仅会被处理一次)

- 整合Kafka手动维护偏移量
  - 手动提交偏移量，就意味着消费了一批数据就应该提交一次偏移量，在SparkStreaming中数据抽象为D Stream，DStream底层其实也就是RDD，即每一批次的数据，因此需要对DStream中的RDD进行处理
  
  ```scala
  kafkaDs.foreachRDD(rdd=>{
      if(rdd.count() > 0){  //如果rdd中有数据则进行处理
        rdd.foreach(record => println("从kafka中消费到的每一条消息：" + record))
        //从kafka中消费到的每一条消息：ConsumerRecord(topic = covid19_material, partition = 0, leaderEpoch = 10, offset = 29, CreateTime = 1654518171097, serialized key size = -1, serialized value size = 7, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = spark)
        // 获取偏移量，使用Sprak-streaming-kafka-0-10中封装好的API来存放偏移量并提交
        val offsets: Array[OffsetRange] = rdd.asInstanceOf[HasOffsetRanges].offsetRanges
        for(o <- offsets) {
          println(s"topics = ${o.topic},partition = ${o.partition},util=${o.untilOffset}")
          //topics = covid19_material,partition = 0,util=30
        }
        // 手动提交偏移量到kafka的默认主题：__consumer__offsets中，如果开启了Checkpoint还会提交到Checkpoint中
        kafkaDs.asInstanceOf[CanCommitOffsets].commitAsync(offsets)
      }
    })
  ```

- 创建 OffsetUtils 整合Kafka手动提交偏移量2
  - 创建OffsetsUtils工具类，将偏移量存储到MySQL中
  - 存入MySQL的偏移量将在```第3步连接kafka获取消息```之前取出并用于连接Kafka
  
  ```scala
   kafkaDs.foreachRDD(rdd=>{
        if(rdd.count() > 0){  //如果rdd中有数据则进行处理
          rdd.foreach(record => println("从kafka中消费到的每一条消息：" + record))
          //从kafka中消费到的每一条消息：ConsumerRecord(topic = covid19_material, partition = 0, leaderEpoch = 10, offset = 29, CreateTime = 1654518171097, serialized key size = -1, serialized value size = 7, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = spark)
          // 获取偏移量，使用Sprak-streaming-kafka-0-10中封装好的API来存放偏移量并提交
          val offsets: Array[OffsetRange] = rdd.asInstanceOf[HasOffsetRanges].offsetRanges
          for(o <- offsets) {
            println(s"topics = ${o.topic},partition = ${o.partition},formOffset = ${o.fromOffset},util = ${o.untilOffset}")
            //topics = covid19_material,partition = 0,util=30
          }
          // 手动提交偏移量到kafka的默认主题：__consumer__offsets中，如果开启了Checkpoint还会提交到Checkpoint中
          // kafkaDs.asInstanceOf[CanCommitOffsets].commitAsync(offsets)
          OffsetUtils.saveOffsets("SparkKafka",offsets)
        }
      })
    ```

## 物资调度管理系统

> **RBAC**

RBAC 即基于角色的权限访问控制（Role-Based Access Control）。这是一种通过角色关联权限，角色同时又关联用户的授权的方式。

# 二、博客系统

## 技术栈

> **Bootstrap**

Bootstrap 是最受欢迎的 HTML、CSS 和 JS 框架，用于**开发响应式布局**、**移动设备优先的 WEB 项目**。

> **Github Oauth**

- 点击登录按钮，后端调用GitHub Authorize接口，GitHub回调函数返回code
- 获取到code之后，通过调用GitHub Access_token接口并携带code，获得token
- 得到token之后，通过调用Github的user接口，即可返回user信息

> **Cookie与session的区别**

- Cookies 是某些网站为了辨别用户身份而储存在用户本地终端上的数据（通常经过加密）
- Session 是服务器端用来存储用户信息的

本项目认证是通过token实现的

> **Mybatis**

- #{}与${} 的区别
  - #{}表示sql语句参数占位符
  - ${} property文件占位符，属于静态文本替换，如${driver}会被静态替换为com.mysql.jdbc. Driver

> **Flyway migration**

数据库移植框架

> **Mybatis Generator**

> **实现回复-事务**

利用`@Transactinoal`注解
# 三、 智能楼宇人员热舒适系统

## 智能楼宇场景下云-边-端通信网络系统

* 项目背景：
  * 科研内容的是对楼宇内人员画像进行构建，对他们的行为进行分析，通过人员反馈和对环境数据进行分析，对人员舒适度进行预测，结合预测数据生成决策实现对相关设备的控制与指令的下发；

  * 关于数据分析与人员热舒适预测部分，于目前主要是以数据-机理双驱动的思想在进行该部分工作

  * 而对环境数据采集和基于边-云协同的决策指令下发的需求，则是通过简历中数据数据采集系统这一项目来满足

  * 最终应用场景为装有300多个传感器，5min采集一次数据并对该数据进行存储，最终需要每日对10w条数据进行采集存储分析，并满足指令的秒级下发。
* 主要工作内容：
  * 整体框架可以分为两部分 端-边(网关)，(网关)边-云(服务器)，目前项目主要工作集中于边-端这一部分的开发，我负责的工作主要是边(网关)的开发，目前还是集中在基于PLC物联网通信协议所构建的网络的性能测试与边端数据的存储与分析工作。

  * 终端侧开发是基于STM32的嵌入式开发，网关侧目前是使用Python开发、数据存储利用SQLite。同时参考了一些企业标准，自己定义了一些数据传输格式和协议进行测试

  * 测试结果：网络时延60ms左右，丢包率根据分布点位不同最好的在1%。 最差的目前丢包率大概在4%。

  * 基于现有测试结果正在将Python实现的功能利用java进行开发，目前主要想解决的是：网络传输丢包率较高的问题，目标是实现万分之一的丢包率

  * 目前开发过程中除了设计满足网络性能指标
  
* 接下来工作重点与难点：
  
  * 终端-边中网络性能与稳定性
  * 从数据的角度来说：向下对端的数据采集、指令下发；向上数据的传输以及云与边的协同的决策；本地数据的存储、上传与更新以及本地网络的管理
  * 考虑到并发与多线程

## 


# 四、数据采集、存储与三维显示系统

* 性能指标
  * 基于Linux操作系统，利用机器人开发平台ROS完成的数据采集、传输与存储，并利用数据实现姿态三维实时显示
  * 整体架构利用ROS平台进行了分布式节点设计，将不同的功能解耦到不同节点，如数据采集节点、数据传输节点、存储节点、三维显示节点，各个节点之间仅关注数据传输，而不关注对方节点的工作原理与细节

  * 数据采集频率为100Hz，并最终以10Hz的频率传回服务器端
  * 服务器端将接收到的数据存储至MySQL数据库，同时实现物体姿态三维实时显示

# 为什么选择荣耀

* 首先我自己家在陕西榆林，包括之前工作在绵阳考研回西安，也是想着毕业在西安，所以在西安荣耀是一个不错的选择，而且去年我师兄师姐对西安荣耀，不管是薪资待遇还是说以后职业发展评价也挺好
  还有一个问题是我自己以后也想做一些关于大数据的相关的工作，所以荣耀既然是做手机终端的，面向消费者，所以从这一点来说也是一个优先的选择。

# 哪个项目好一点

从本科毕业到现在自己做过的项目大概有：

* 工作期间做过的关于硬件的项目，这部分内容跟现在软开的工作相关性不大，但是通过这些项目从另一个角度对项目从需求分析、方案设计、方案论证实现包括后续的研发，成本控制这些东西有了一个初步的认识

* 研究生期间做过的项目

  * 数据采集、存储与三维显示系统主要是基于Linux操作系统开发的一个项目，项目在数据采集这一侧是利用树莓派开发的，所以工作内容更偏向嵌入式开发。
      这个项目其实遇到的主要问题是数据采集端与服务器端保证数据实时传输时容易受到干扰的问题。
      然后还有通过ROS系统体会到了一种设计思想，也就是说各个节点独立工作，节点与节点之间只关心数据的流动，而节点的管理交给服务器去管理

  * 传感器网络构建：这个项目背景有一部分是因为在做人群热舒适的刻画，所以对数据处理与分析有一定的掌握；
      相比于数据采集三维显示的那个项目，这个项目难度更高，目前也是在一点一点摸索去实现
      目前的难点的话，主要是网络性能的实现，单从硬件性能来说，网络时延60ms左右，丢包率根据分布点位不同最好的在1%。 最差的目前丢包率大概在4%。所以需要通过借鉴现有的传输体系，在我应用层通过编程实现万分之一的丢包率
      而且现在正在做的需求调研，后续对云和边的功能与架构体系设计与实现可能是最难的一部分。

  * 除了上述项目之外，还做过一些简单的web应用开发，有用Nodejs + Vue实现，还有自己目前正在学习的一些关于SpringBoot的web开发，还有微服务的项目。这些项目主要是想自己从头到尾做一些真正的软件开发的项目，给自己打好基础
