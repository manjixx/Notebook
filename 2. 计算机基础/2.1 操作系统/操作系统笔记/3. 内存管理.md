
# 一、 虚拟内存

操作系统为了保证每个进程之间独立运行，互不干涉，因此操作系统为每个进程分配一条独立的「虚拟地址」。

操作系统将提供一种机制将不同地址的虚拟地址与不同内存的物理地址映射起来。

> **虚拟内存与物理内存**

- 虚拟内存：程序中所使用的内存地址称之为虚拟内存地址(Virtual Memory Address)
- 物理内存地址:实际硬件中的空间地址称之为物理内存地址(Physical Memory Address)

> **操作系统如何管理虚拟地址与物理地址之间的映射**

为了将虚拟地址映射为物理地址，CPU会通过内存管理单元(MMU)来实现虚拟地址到物理地址的映射
![MMU](https://camo.githubusercontent.com/47e668d7a49fdadefafb9748d5ee814c74559a508c1f7a33fd6013c3a235f58d/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f37326162373662613639376534373062386365623134643566633536383864392e706e67)

**实现方式主要有两种：**

- 内存分段
- 内存分页
  
---

# 二、 内存分段

程序是由若干个逻辑分段组成的，如可由**代码分段、数据分段、栈段、堆段**组成。不同的段是有不同的属性的，所以**就用分段（Segmentation）的形式把这些段分离出来。**

## 2.1 分段机制下虚拟地址与物理地址实现映射

分段机制下，虚拟内存由两部分组成：

- 段选择因子：由段号和特权等标志位组成，段选择因子保存在段寄存器中。其中最重要的是段号，段号用作段表的索引，可以从段表中获取段的基地址、段界限与特权等级等信息。

- 段内偏移量： 位于0与段界限之间，如果段内偏移量是合法的，就将**段基址+段内偏移量=物理地址的内存地址**

![内存分段中虚拟地址与物理地址的映射](https://camo.githubusercontent.com/143888df2efd78708a2150ae02a444b0bcd9800dbc3db3e3aa540fe23ddc6d65/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f61396564393739653265643834313466393832383736373539326161646332312e706e67)

> **虚拟地址到物理地址的映射**

分段机制会将虚拟地址分为四个段，每个段在段表中有一项，通过该项可以确定段基址，段基址+段偏移量便可确定物理地址
![](https://camo.githubusercontent.com/243947967676effbf4b510ab72c397afc35ca15b15403510ff1d9e8e419a980c/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f63356532616236336536656534633864623537356633633763396338353936322e706e67)

## 2.2 内存分段存在的问题

> **内存分段存在的问题**

- 内存碎片
- 内存交换效率低下

### 2.2.1 内存碎片

> **内存碎片产生的原因**

假设有1G内存，用户执行如下程序

- 游戏占内存512MB
- 浏览器占内存128MB
- 音乐占用内存256MB
- 空闲内存 128MB
如果此时关闭浏览器，那么空闲内存为256MB， 但二者不连续，因此需要打开200MB的内存会失败

![内存碎片举例](https://camo.githubusercontent.com/b42818f152c20e23c38321c98794927a80ce22903fb5137ec8d0596bcc147638/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f36313432626333633931376534613632393862646236323933366530643333322e706e67)

> **内存碎片分类**

- 外部内存碎片:即产生多个不连续的小物理内存，导致新的程序无法被加载
- 内部内存碎片:加载后的内存，可能存在使用频率低的内存，因此导致内存浪费

> **解决方案**

解决外部内存碎片问题的方案就是**内存交换**

可以将音乐占用的256MB内存写到硬盘上，然后从硬盘上读回内存中，读回时需要将音乐程序装载到连续的512MB内存空间后面，这样就能空缺连续的256MB空间。

Linux 系统里的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。

### 2.2.2 内存交换效率低

对多进程系统而言，分段的方式会产生很多内存碎片，需要用`swap`内存区域，因为硬盘的访问速度比内存慢，每一次交换内存，需要将大量数据写到硬盘上，该过程会产生性能瓶颈。

如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。

为了解决内存分段的内存碎片问题与内存交换效率低的问题，出现了内存分页。

# 三、 内存分页

## 3.1 分页机制

分页:是将整个虚拟内存和物理内存切割为一段固定尺寸大小，这样连续并固定尺寸的内存空间，我们称之为也(page)。Linux下，每一页的大小为`4KB`。

虚拟地址与物理地址之间通过**页表**来映射，如下图:
![页表](https://camo.githubusercontent.com/e12fe2068b9efe6483699ef74dd1cf00fc7a24cb30fcefbd1c0f1ea9d0672ae8/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f30386138653331356665646334613835383036306462356362346136353461662e706e67)

页表存储在内存里，内存管理单元MMU负责将虚拟地址转换为物理地址

当进程访问的虚拟地址在页表中查询不到的时，就会产生缺页异常，进入系统内核空间分配物理内存，更新进程页表，最后再返回用户态，恢复进程运行。

## 3.2 分页如何解决内存碎片与内存交换效率低的问题

- 内存碎片: 因为采用了分页内存管理，释放的内存均是通过页来释放的，因此不会产生无法给进程使用的小内存。

- 内存交换效率低
  - 如果内存空间不够，操作系统会将进程中「最近没被使用」的内存页面暂存到硬盘上，称之为换出(Swap out)。需要时则将其加载进来，称之为换入(Swap in)。所以一次性写入磁盘的也只有少数的页面，花费时间较少，内存交换效率低。
  - 其次运行程序时，我们可以只将用到的对应虚拟内存页面里的指令和数据时，将对应页面加载到物理内存中去。

## 3.3 分页机制下，虚拟地址与物理地址的映射

分页机制下虚拟地址分为两部分

- 页号:页号作为页表的索引，页表包含页在物理内存中的基地址
- 页内偏移量
- **基地址 + 页内偏移量 = 物理内存地址**

![分页机制下虚拟地址与物理地址的映射](https://camo.githubusercontent.com/f8de9f8e6028fa86802790852fa243aafc13db4c3d645f4a520304ae705e9483/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f37383834663464386462343934396637613562623462626430663435323630392e706e67)

> **简单分页的缺陷**

因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。

在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。

这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。

那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。

## 3.4 多级页表

为了解决单页表占用内存空间大的问题，采用一种叫作多级页表（Multi-Level Page Table）的解决方案。

对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于页表需占用 4MB 大小的空间。

将 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：

![二级页表](https://camo.githubusercontent.com/948df7c1a98458144d60a61137d9751c729a060fa79adfe01f32346711a1feb9/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f31393239366532343962323234306332396639633532626537306636313164352e706e67)

> **为什么二级页表会节约存储空间**

计算机组成原理里面无处不在的局部性原理

- 对于单页表：即使进程没有使用物理内存，页表就需要有 100 多万个页表项来映射，整个页表占用4MB的内存空间

- 对于多级页表:使用一级页表覆盖整个物理空间需要1024个页表项，而二级页表在需要时创建，如果此时仅需要20%的页表，此时页表占用内存空间为:4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`

> **64位系统的四级目录**

- 全局页目录项 PGD (Page Global Directory)
- 上层页目录项 PUD (Page Upper Directory)
- 中间页目录项 PMD (Page Middle Directory)
- 页表项 PTE (Page Table Entry)

![四级目录](https://camo.githubusercontent.com/d5a244a2dbfbfe175b0a0f603861ad9c3431b2b12b16bed57cd673c17c2da680/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545362539332538442545342542442539432545372542332542422545372542422539462f2545352538362538352545352541442539382545372541452541312545372539302538362f2545352539422539422545372542412541372545352538382538362545392541312542352e706e67)

> **TLB (Translation Lookaside Buffer)**

多级页表可以有效缓解空间上的问题，但是存在地址转换的速度，带来时间上的开销。

由于**程序的局部性**，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

![访问频率与内存地址](https://camo.githubusercontent.com/1edeee0a17f41c13f6c85af4e955c84f220a8babba50a2c1853861d761b969e4/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f65646365353835333464393334326666383966353236316231393239633735342e706e67)

基于上述特性，将经常访问的页表项存储到速度更快的硬件中，因此在CPU中引入了存放程序经常访问的页表项cache，即TLB 通常称为页表缓存、转址旁路缓存、快表等。

![TLB](https://camo.githubusercontent.com/df34816746a81eb0df9f43175d94b49dc3a9f88c341607701812e38a1dd52382/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f61336364663237363436623234363134613634636663356437636366666133352e706e67)

引入TLB后，CPU寻址时，首先会查TLB，如果没找到则继续查找常规的页表。

# 四、 段页式内存管理

> **段页式内存管理的实现方式**

- 先将程序划分为多个逻辑段，即之前的分段机制
- 再将每个段划分为多个段，即对分段分出来的连续空间再划分为固定大小的页

> **段页式内存管理**

段页式内存管理的虚拟地址构成：

- 段号
- 段内页号
- 页内偏移地址

> **段页式内存变换**

段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号

![段页式地址](https://camo.githubusercontent.com/4803140ac7878cc56f72505548392a9f8f2a8592c8c2b5c0f1cfc69e2e6d7901/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f66313965626436663730663834303833623064383763633565396465613865332e706e67)

段页式地址变换得到物理地址必须经过三次内存访问:

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号
- 第三次将`物理页号 + 页内偏移地址 = 物理地址`

# 五、 Linux内存管理

> **Intel 处理器的发展历史**

- 80286：段页式内存管理
- 80386：段式内存管理的基础上实现了页式内存管理，页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。
  - 逻辑地址(程序段内偏移量)：程序所使用的地址，通常是没被段式内存管理映射的地址
  - 虚拟地址：通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址
  ![](https://camo.githubusercontent.com/24fc2f9a0140ade1bfd0bbf707362482948170a933a1b624bdc517fcbdc1584e/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f38393034666238396165306334396334623066326637623561306137623039392e706e67)

> **Linux系统的内存管理**

因为Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射，所以**Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。**

**Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。**

这意味着 Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护

![](https://camo.githubusercontent.com/2bcb7cab697e23196e292b169a4422fa45112916b8905430420dc761f0dfcf2c/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f62633061616166333739666334626338383832656664393462393035326236342e706e67)

> **Linux虚拟地址空间如何分布**

- 内核空间与用户空间
  - 进程在用户态时，只能访问用户空间内存
  - 只有进入内核态后，才可以访问内核空间的内存；

- 虚拟地址空间分布
  - `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
  - `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的

虽然**每个进程都各自有独立的虚拟内存**，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。以保证用户进入内核态之后，可以方便地访问内核空间内存。

![](https://camo.githubusercontent.com/3148b0621f1f99e84d3741e9c5b1fd9156881a9e065044ee464af41371d4a754/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f33613663623465336632373234316433623039623437363662623062313132342e706e67)

- 用户空间的分布情况,有下图可以看出从低到高分别是7中不同内存段:
  - 程序文件段，包括二进制可执行代码
  - 已初始化的数据段，包括静态常量
  - 未初始化的数据段，未初始化的静态变量
  - 堆段，包括动态分配的内存，地址从低到高递增
  - 文件映射段，包括动态库、内存共享，从低到高地址递增
  - 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`当然系统也提供了参数，以便我们自定义大小；
![用户空间内存分布](https://camo.githubusercontent.com/5a5ae4af45f41dce2cd8162fd3e56ba245e5d764b358477a8692c4ebd6f106d7/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f62346638383262393434373736306365353332316465313039323736656332332e706e67)

在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。

# 六、 页面置换算法

## 6.1 缺页异常

在了解内存页面置换算法前，我们得先谈一下**缺页异常（缺页中断）**。

当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：

- 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
- 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。

我们来看一下缺页中断的处理流程，如下图：

![缺页中断的处理流程](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/缺页异常流程.png)

1. 在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。
2. 如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
3. 操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
4. 找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。
5. 页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
6. 最后，CPU 重新执行导致缺页异常的指令。

上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？

找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。

这里提一下，页表项通常有如下图的字段：

![](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/页表项字段.png)

那其中：

- *状态位*：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
- *访问字段*：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
- *修改位*：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
- *硬盘地址*：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。


这里我整理了虚拟内存的管理整个流程，你可以从下面这张图看到：

![虚拟内存的流程](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/虚拟内存管理流程.png)


所以，页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。

那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：

- 最佳页面置换算法（*OPT*）
- 先进先出置换算法（*FIFO*）
- 最近最久未使用的置换算法（*LRU*）
- 时钟页面置换算法（*Lock*）
- 最不常用置换算法（*LFU*）

## 6.2 最佳页面置换算法

最佳页面置换算法基本思路是，**置换在「未来」最长时间不访问的页面**。

所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。


我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![最佳页面置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/最优置换算法.png)

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。

所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

## 6.3 先进先出置换算法

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。

还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：


![先进先出置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/FIFO置换算法.png)


在这个请求的页面序列中，缺页共发生了 `10` 次，页面置换共发生了 `7` 次，跟最佳页面置换算法比较起来，性能明显差了很多。


## 6.4 最近最久未使用的置换算法

最近最久未使用（*LRU*）的置换算法的基本思路是，发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。


还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

![最近最久未使用的置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/LRU置换算法.png)


在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟先进先出置换算法比较起来，性能提高了一些。


虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

## 6.5 时钟页面置换算法

那有没有一种即能优化置换的次数，也能方便实现的算法呢？

时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。

该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

当发生缺页中断时，算法首先检查表针指向的页面：

- 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
- 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：

![时钟页面置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/操作系统/调度算法/时钟置换算法.png)

了解了这个算法的工作方式，就明白为什么它被称为时钟（*Clock*）算法了。

## 6.6 最不常用算法

最不常用（*LFU*）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。

它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。

---