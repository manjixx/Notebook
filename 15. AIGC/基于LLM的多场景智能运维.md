# 基于LLM的多场景智能运维

本文介绍了SRE-Copilot团队在AIOps挑战赛中的方案，利用大语言模型构建了一个多场景智能运维框架，通过底层专家Agent处理不同模态数据，上层功能类Agent实现故障诊断、知识问答等，展示了ReAct和RAG框架的应用，以及如何通过LLM进行异常检测和根因定位，有望解决企业运维中的复杂挑战。

## 一、背景

赛题分析
本次赛题为开放性赛题，探讨的是大语言模型在AIOps领域的应用，基于建行稳定性系统模拟建行生活类APP的真实环境，希望解决企业运维团队面对规模庞大、结构复杂、动态变化的运维数据需要解决的一系列挑战（系统架构复杂，数据量庞大，数据种类多等）。

## 二、整体框架

SRE-Copilot：一套基于大语言模型的多场景智能运维框架，这套框架支持**多个智能体Agent的协作与动态编排调度**，有计划，记忆，反思与推理等能力，为SRE同学提供智能化服务。我们参考了GPT的思想，也就是通过集成学习的方式，用多个专业的子Agent组合成强大的混合专家(`MoE,Mixture of Experts`)系统。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/5EcwYhllQOiakd9FsaE1gHyXtibVWCRxM9cvoUJUQHnBPHKhSnVZ03xA56nRGUO1jpUecpVZgyyYbL5OfUMO57Dg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

针对本次比赛提供的多种模态的数据，构建了多个底层的专家Agent，包括：

- 日志类 `LogAgent`：负责对日志类型数据进行异常检测，对日志数据进行检索，根据集群筛选日志
- 调用链类型 `TraceAgent`：负责对调用链数据进行异常检测，进行简单的诊断。
- 交易类型 `TradeAgent`：对交易量等黄金指标进行异常检测
- 主机类型 `MonitorAgent`：对主机类型数据，包括cpu，负载，网络等进行异常检测
- 拓扑类型 `CMDBAgent`：对CMDB信息进行关联，提取&查询CMDB信息 其他：未来对其他类型数据可自由拓展

**在上层定义了多个功能类 Agent**，包括故障诊断，知识库问答，工作流生成，故障报告生成，代码编写等

在**整体架构**上我们通过大语言模型把全部功能组合起来，实现意图识别，参数提取，任务调度等功能。

## 三、技术性与创新性

### 3.1 基于 ReAct 框架和CoT思维链的 Multi-Agent 编排调度，实现了多模态数据按需异常检测

ReAct 的思想参考自论文《ReAct: Synergizing Reasoning and Acting in Language Models》，包括推理（Reasoning）和行动（Action），推理帮助模型生成、追踪和更新计划并处理异常，行动允许模型与外部环境交互以获取更多信息Observation，提升准确率与适应性。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/5EcwYhllQOiakd9FsaE1gHyXtibVWCRxM9sjia2LR8QUxTCqKsmpPMbEvHaNibBtGbDEOTFMrwbkW4rczNYTTqN2dw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 在异常检测场景中，首先**定义多数据源Agent**，分别负责选择合适的算法对不同模态数据进行异常检测与检索;
- **主持人 Copilot 负责解析用户意图**
- `RCAAgent` 负责收集其他 Agent 检测到的异常结果与链路、配置信息，进行根因定位。

**实例**

如上图所示，用户提问中提到“交易大量失败”，此时模型会将问题交给负责交易数据的`TradeAgent`进行检测，`TradeAgent`检测得出“交易性能下降”，则问题会进一步交给负责性能数据的`MonitorAgent`。通过这种模式，将排障流程进行下去，每个`Agent`的检测顺序及内容均根据检测到的异常动态编排。`RCAAgent`负责收敛协作轮次，并根据反馈决定下一步分析与下钻的方向，当没有额外信息时，就会停止检测，进行根因定位。

我们会构造如下 prompt

![](https://img-blog.csdnimg.cn/direct/82dec032c7c34206abe869d8dfe0e58b.png)

此时模型会见问题抛给 TradeAgent

![](https://img-blog.csdnimg.cn/direct/f0acff603e134fe08fba077e261a8790.png)

通过这种模式，将排障流程进行下去，每个Agent各司其职，我们也对异常检测插件进行了改造，不同于传统的异常检测算法，只返回单独的True/False信息，我们让插件返回故障时刻的描述，更加利于大语言模型的理解，例如：“CPU指标出现突增，网络出入流量突增”，当发现没有额外信息后，就会停止检测，进行根因定位。

`SRE-Copilot`模拟了真实的大规模云平台跨组件协同定位，利用多个`Agent`替代多个组件运维团队，发挥各自所长，并动态编排决定排查方向；同时，`SRE-Copilot`更关注多个组件（多个数据）的表现形态，而非根据单一组件（单一数据）判断是否异常，降低噪声，具有更高的鲁棒性。

### 3.2 基于 RAG 检索增强的框架进行根因推理

**检索增强生成 (RAG)** 是使用来自私有或专有数据源的信息来辅助文本生成的技术。它将检索模型（用于搜索大型数据集或知识库）和生成模型（使用检索到的信息生成可供阅读的文本回复）结合在一起，通过从更多数据源添加背景信息，比如训练 LLM 时并未用到的互联网上的新信息、专有商业背景信息或者属于企业的内部文档等，来补充LLM原始知识库，改善大型语言模型的输出，使生成的答案更可靠，还有助于缓解“幻觉”问题，且不需要重新训练。

**根因定位过程主要包含如下过程：**

- **知识库构建**：需要提前定义一些专家诊断经验和历史故障库，并将信息转化为高维度空间中的向量，存储在向量数据库中。专家经验可以由运维工程师或者业务专家来定义，比如：流量突增，内存打满，服务不可用，对应的可能是大量访问带来的问题，此时应该扩容或重启等。

- **RAG检索增强**：使用异常检测生成的故障摘要作为输入，对历史故障、专家经验、知识库文档等进行检索，检索的 TopN 结果作为上下文和原始提示词组合，再提交给 LLM 进行根因定位。LLM 的参数化知识是静态的，**RAG 让 LLM 不用重新训练就能获取最新相关信息，提升了模型的准确性和实时性**。

- **推理与反思**：由于本次比赛使用的是6b的小模型（兼容本地化部署环境），推理稳定性较差，因此引入“反思”机制，让模型对自己诊断的根因进行再次判断，进一步提高了根因定位的准确度。

- **学习新的策略**：每次诊断结果既会生成诊断报告，也会加入模型记忆，再次诊断时对最相近的专家经验与诊断结果进行推理，让模型获得持续学习与迭代的能力。

基于 RAG，即使是小模型，在没有专家经验和历史故障的输入时，仍然能对一些简单问题进行根因推断，例如：**磁盘写满故障、java虚拟机GC问题等等**。通过让模型进行自我评估和自我反省，能够将模型推理根因的准确率进一步提升 30% 以上 。模型在诊断过程中能够不断迭代、持续学习，随着学习和推理的逐渐完善，`SRE-Copilot` 故障诊断的能力也将不断提升。

### 3.3 辅助运维能力

![](https://mmbiz.qpic.cn/sz_mmbiz_png/5EcwYhllQOiakd9FsaE1gHyXtibVWCRxM94jam0w7jC6BtmBpq63Wp2mw19VHHykYgchv9TOR1sjDfS9vtLU4o5Q/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

基于大语言模型使用 `tools` 的能力，把散落的各个运维场景进行统一集成，理解、拆分用户意图，编排调用不同工具，提供稳定性建设全流程的智能运维能力。用户可通过自然语言提问方式使用 `SRE-Copilot` 框架的以下运维能力：

- 运维计划：解析用户运维需求，生成自然语言的工作流，并从系统可调用的组件中选择合适组件，动态生成可执行的工作流；
- 运维可视化：通过自然语言交互，自动执行简易的数据查询/分析，对故障数据进行可视化；
- 异常检测：支持多模态数据类型，灵活拓展，通过多Agent协同编排，整合不同平台数据，极大缩短MTTR；
- 根因定位：无监督，支持专家经验、历史故障输入，对已知故障准确率高，对于未知故障可推理；
- 故障分类：根据专家经验和历史故障所属类别，以及本次故障表现，对故障进行分类，有助于后续按组织或改进措施推进复盘与优化；
- 故障自愈：在推理得到故障根因和故障分类后，可以推荐合适的自愈措施，流程自动化，让运维人员集中精力，无需频繁切换上下文，确保响应和处理的及时性和准确性 ；
- 代码生成：基于用户的提示生成代码，将复杂脚本的调试开发时间从几小时缩短到几分钟；
- 故障报告：利用LLM自动生成故障诊断报告，以自然语言方式表述5W问题：`When-Where-Who-What-Why`，显著提升故障诊断报告的效率与质量，方便团队积累经验和知识库 ；
- 知识库问答：基于本地知识库进行私域知识问答，提升应答准确率，减少`Oncall`系统人力投入。

## 四、总结与展望

我们觉得将大语言模型引入到AIOps领域，可能会解决一些AIOps领域的痛点问题，比如：

**总结**

![](https://img-blog.csdnimg.cn/direct/48ae06447b7b433cad69984d432e4bce.png)

- 当前各个公司的系统架构愈发复杂，各种组件依赖越来越多，很难有一个专家，甚至一个团队精通全部架构/组件的技术细节。当发现问题时候，通常是快速拉起多个组件的同学进行协同定位。而LLM可以学习近乎无限的知识，也可以通过设计多个专家Agent的方式进行编排调度无限拓展。
- 传统AIOps算法大多依赖统计方法，异常检测&根因诊断大部分算法都依赖于数据的标注。专家的经验很难编码到模型里，而LLM基于检索增强的方式，极大地降低数据标注成本和重新训练的成本。
- 在接入维护方面，传统AIOps当遇到新客户/私域知识/业务经验/数据变动等情况时，通常只能重新训练，而通过多Agent多方式，客户甚至可以将自己的逻辑经验轻松接入。
- 对于未知的故障，由于没有训练过，传统AIOps算法无法推理，但是LLM通过通用知识的学习，可以进行一些简单的推断。
- 最后就是在交互方面，LLM也极大地降低了交互成本，让用户更加易用。

**未来展望**

![](https://img-blog.csdnimg.cn/direct/bf32c195a1c249bcbe86818a85889991.png)